{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Important Note for question1 !\n",
    "- Please **do not** change the default variable names in this problem, as we will use them in different parts.\n",
    "- The default variables are initially set to \"None\".\n",
    "- You only need to modify code in the \"TODO\" part. We added a lot of \"assertions\" to check your code. **Do not** modify them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P1. Load data and plot\n",
    "### TODO\n",
    "- Load train and test data, and split them into inputs(trainX, testX) and labels(trainY, testY)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas to load q1_train.csv and q1_test.csv\n",
    "# Each data point has 200 features(X), followed by 1 label(Y)\n",
    "\n",
    "#### TODO ####\n",
    "trainX = pd.read_csv('q1_train.csv',index_col=0)\n",
    "trainY = trainX.iloc[:,200]\n",
    "trainX = trainX.drop(columns=['200'])\n",
    "\n",
    "\n",
    "testX = pd.read_csv('q1_test.csv',index_col=0)\n",
    "testY = testX.iloc[:,200]\n",
    "testX = testX.drop(columns=['200'])\n",
    "##############\n",
    "\n",
    "assert(len(trainX.shape) == 2)\n",
    "assert(len(trainY.shape) == 1)\n",
    "assert(trainX.shape[1] == 200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P2. Write your Gaussian NB solver\n",
    "### TODO\n",
    "- Finish the myNBSolver() function. \n",
    "    - Compute P(y == 0) and P(y == 1), saved in \"py0\" and \"py1\"\n",
    "    - Compute mean/variance of trainX for both y = 0 and y = 1, saved in \"mean0\", \"var0\", \"mean1\" and \"var1\"\n",
    "        - Each of them should have shape (N_train, M), where N_train is number of train samples and M is number of features.\n",
    "    - Compute P(xi | y == 0) and P(xi | y == 1), compare and save **binary** prediction in \"train_pred\" and \"test_pred\"\n",
    "    - Compute train accuracy and test accuracy, saved in \"train_acc\" and \"test_acc\".\n",
    "    - Return train accuracy and test accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myNBSolver(trainX, trainY, testX, testY):\n",
    "    \n",
    "    N_train = trainX.shape[0] #number training samples\n",
    "    N_test = testX.shape[0]   #number test samples\n",
    "    M = trainX.shape[1]       #number of features\n",
    "    \n",
    "    #### TODO ####\n",
    "    # Compute P(y == 0) and P(y == 1)\n",
    "    zero_array = np.where(trainY.astype(int) == 0)[0]\n",
    "    ones_array = np.where(trainY.astype(int) == 1)[0]\n",
    "\n",
    "    py0 = len(zero_array)/N_train\n",
    "    py1 = len(ones_array)/N_train\n",
    "    \n",
    "    ##############\n",
    "    print(\"Total probablity is %.2f. Should be equal to 1.\" %(py0 + py1))\n",
    "\n",
    "    #### TODO ####\n",
    "    # Compute mean/var for each label\n",
    "    \n",
    "    # split your X into two subsets based on label y (0 or 1), and then compute mean and variance of each subset\n",
    "    X_y0 = trainX.iloc[zero_array]\n",
    "    X_y1 = trainX.iloc[ones_array]\n",
    "    mean0 = np.mean(X_y0)\n",
    "    mean1 = np.mean(X_y1)\n",
    "    var0 = np.var(X_y0)\n",
    "    var1 = np.var(X_y1)\n",
    "    \n",
    "    ##############\n",
    "    assert(mean0.shape[0] == M)\n",
    "    \n",
    "    #### TODO ####\n",
    "    # Compute P(xi|y == 0) and P(xi|y == 1), compare and make prediction\n",
    "    # This part may spend 5 - 10 minutes or even more if you use for loop, so feel free to \n",
    "    # print something (like step number) to check the progress\n",
    "    \n",
    "    #Compute P(xi | y == 0) and P(xi | y == 1), compare and save binary prediction in \"train_pred\" and \"test_pred\"\n",
    "    \n",
    "    # calculate P(xi|y=0) and P(xi|y=1)\n",
    "    train_pred = np.empty((N_train))\n",
    "    test_pred = np.empty((N_test))\n",
    "    \n",
    "    # For train data\n",
    "    P_xi_y0 = (1/ np.sqrt(2*np.pi*(var0**2))) * np.exp( (-(trainX - mean0)**2)/ (2*var0**2) )\n",
    "    P_xi_y1 = (1/ np.sqrt(2*np.pi*(var1**2))) * np.exp( (-(trainX - mean1)**2)/ (2*var1**2) )\n",
    "\n",
    "    # product of probabilities \n",
    "    prod_y0 = np.prod(P_xi_y0, axis=1)\n",
    "    prod_y1 = np.prod(P_xi_y1, axis=1)\n",
    "\n",
    "    Prob_y1_x = (prod_y1*py1)/ ( (prod_y1*py1) + (prod_y0*py0) )\n",
    "    Prob_y0_x = (prod_y0*py0)/ ( (prod_y0*py0) + (prod_y1*py1) )\n",
    "\n",
    "    for i in range(N_train):\n",
    "        if Prob_y0_x[i] > Prob_y1_x[i]:\n",
    "            train_pred[i] = 0\n",
    "        else:\n",
    "            train_pred[i] = 1\n",
    "            \n",
    "    # For test data\n",
    "    Pt_xi_y0 = (1/ np.sqrt(2*np.pi*(var0**2))) * np.exp( (-(testX - mean0)**2)/ (2*var0**2) )\n",
    "    Pt_xi_y1 = (1/ np.sqrt(2*np.pi*(var1**2))) * np.exp( (-(testX - mean1)**2)/ (2*var1**2) )\n",
    "\n",
    "    tprod_y0 = np.prod(Pt_xi_y0, axis=1)\n",
    "    tprod_y1 = np.prod(Pt_xi_y1, axis=1)\n",
    "\n",
    "    Prob_y1_tx = (tprod_y1*py1)/ ( (tprod_y1*py1) + (tprod_y0*py0) )\n",
    "    Prob_y0_tx= (tprod_y0*py0)/ ( (tprod_y0*py0) + (tprod_y1*py1) )\n",
    "\n",
    "    for i in range(N_test):\n",
    "        if Prob_y0_tx[i] > Prob_y1_tx[i]:\n",
    "            test_pred[i] = 0\n",
    "        else:\n",
    "            test_pred[i] = 1\n",
    "\n",
    "\n",
    "    ##############\n",
    "    assert(train_pred[0] == 0 or train_pred[0] == 1)\n",
    "    assert(test_pred[0] == 0 or test_pred[0] == 1)\n",
    "    \n",
    "    #### TODO ####\n",
    "    # Compute train accuracy and test accuracy\n",
    "    test_counter = 0\n",
    "    train_counter = 0\n",
    "    \n",
    "    for i in range(N_train):\n",
    "        if train_pred[i].astype(int) == trainY[i].astype(int):\n",
    "            train_counter += 1\n",
    "            \n",
    "    for i in range(N_test):\n",
    "        if test_pred[i].astype(int) == testY[i].astype(int):\n",
    "            test_counter += 1    \n",
    "    train_acc = train_counter/N_train\n",
    "    test_acc = test_counter/N_test\n",
    "    \n",
    "    ##############\n",
    "    \n",
    "    return train_acc, test_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total probablity is 1.00. Should be equal to 1.\n",
      "Train accuracy is 92.07\n",
      "Test accuracy is 91.90\n"
     ]
    }
   ],
   "source": [
    "# driver to test your NB solver\n",
    "train_acc, test_acc = myNBSolver(trainX, trainY, testX, testY)\n",
    "print(\"Train accuracy is %.2f\" %(train_acc * 100))\n",
    "print(\"Test accuracy is %.2f\" %(test_acc * 100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## P3. Test your result using sklearn\n",
    "### TODO\n",
    "- Finish the skNBSolver() function. \n",
    "     - fit model, make prediction and return accuracy for train and test sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def skNBSolver(trainX, trainY, testX, testY):\n",
    "    \n",
    "    #### TODO ####\n",
    "    # fit model\n",
    "    # make prediction\n",
    "    # compute accuracy\n",
    "    \n",
    "    model = GaussianNB()\n",
    "    model.fit(trainX,trainY)\n",
    "    predicted_train = model.predict(trainX) \n",
    "    \n",
    "    predicted_test = model.predict(testX) \n",
    "    \n",
    "    test_counter = 0\n",
    "    train_counter = 0\n",
    "    \n",
    "    for i in range(len(trainX)):\n",
    "        if predicted_train[i].astype(int) == trainY[i].astype(int):\n",
    "            train_counter += 1\n",
    "            \n",
    "    for i in range(len(testX)):\n",
    "        if predicted_test[i].astype(int) == testY[i].astype(int):\n",
    "            test_counter += 1 \n",
    "            \n",
    "    sk_train_acc = train_counter/len(trainX)\n",
    "    sk_test_acc = test_counter/len(testX)\n",
    "    \n",
    "    ##############\n",
    "    return sk_train_acc, sk_test_acc\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train accuracy is 92.22\n",
      "Test accuracy is 92.05\n"
     ]
    }
   ],
   "source": [
    "# driver to test skNBSolver\n",
    "sk_train_acc, sk_test_acc = skNBSolver(trainX, trainY, testX, testY)\n",
    "print(\"Train accuracy is %.2f\" %(sk_train_acc * 100))\n",
    "print(\"Test accuracy is %.2f\" %(sk_test_acc * 100))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
